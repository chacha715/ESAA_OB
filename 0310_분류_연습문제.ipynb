{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chacha715/ESAA_OB/blob/main/0310_%EB%B6%84%EB%A5%98_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCu72vDHGMHo"
      },
      "source": [
        "## **| 분류 연습 문제**\n",
        "___\n",
        "출처 : 핸즈온 머신러닝 Ch03 분류 연습문제 1, 2번"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBMD6RMQJcnZ",
        "outputId": "c24e733b-f3f3-4da8-b27e-223e13bd13ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# import data\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version = 1, as_frame = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0acMMz8YKS7v"
      },
      "outputs": [],
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0KzCWYFg6CPP"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      },
      "source": [
        "### **1. MNIST 데이터셋으로 분류기를 만들어 테스트 세트에서 97% 정확도를 달성해보세요.**\n",
        "___\n",
        "\n",
        "1. `KNeghtborsClassifier`를 사용하는 것을 추천합니다. \n",
        "2. `weights`와 `n_neighbors` 하이퍼 파라미터로 그리드 탐색을 시도하여, 좋은 하이퍼 파라미터 값을 찾아보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "188lZyYEGJZ7"
      },
      "outputs": [],
      "source": [
        "# import package\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXF4M2MdIpKa",
        "outputId": "e1c63347-9ff7-4b81-c55e-6f4a1d5964ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
          ]
        }
      ],
      "source": [
        "# Try GridSearch to optimize hyperparameter\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors' : [3,4,5],\n",
        "    'weights' : [\"uniform\", \"distance\"],\n",
        "    'metric' : ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "knn_grid = GridSearchCV(knn_clf,\n",
        "                        parameters,\n",
        "                        cv = 3,\n",
        "                        n_jobs = -1,\n",
        "                        verbose = True)\n",
        "knn_grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0NiljKhJJlj"
      },
      "outputs": [],
      "source": [
        "# best hyperparameter\n",
        "print(knn_grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPLNro_xJTrx"
      },
      "outputs": [],
      "source": [
        "# best score\n",
        "print(knn_grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVY_c-DMJX70"
      },
      "outputs": [],
      "source": [
        "# model test\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = grid_search.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pDjW5XcHPOt"
      },
      "source": [
        "### **2. 다음 단계를 따라 인위적으로 훈련 세트를 늘리는 데이터 증식 또는 훈련 세트 확장 기법을 연습해봅시다.**\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xhEB_KtH47q"
      },
      "source": [
        "#### **STEP 1. MNIST 이미지를 (왼, 오른, 위, 아래) 어느 방향으로든 한 픽셀 이동시킬 수 있는 함수를 만들어 보세요.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKw9INbrJgpv"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage.interpolation import shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CLxYCROIAk6"
      },
      "outputs": [],
      "source": [
        "def shift_image(image, dx, dy):\n",
        "    image = image.reshape((28, 28))\n",
        "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
        "    return shifted_image.reshape([-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHgSqi-zIBCd"
      },
      "source": [
        "####  **STEP 2. 앞에서 만든 함수를 이용하여, 훈련 세트에 있는 각 이미지에 대해 네 개의 이동된 복사본(방향마다 한 개씩)을 만들어 훈련 세트에 추가하세요**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsBT_d0MIH-V"
      },
      "outputs": [],
      "source": [
        "image = X_train[1000]\n",
        "shifted_image_down = shift_image(image, 0, 5)\n",
        "shifted_image_left = shift_image(image, -5, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS1empJzKCOG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,3))\n",
        "plt.subplot(131)\n",
        "plt.title(\"Original\", fontsize=14)\n",
        "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.subplot(132)\n",
        "plt.title(\"Shifted down\", fontsize=14)\n",
        "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.subplot(133)\n",
        "plt.title(\"Shifted left\", fontsize=14)\n",
        "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_augmented = [image for image in X_train]\n",
        "y_train_augmented = [label for label in y_train]\n",
        "\n",
        "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
        "    for image, label in zip(X_train, y_train):\n",
        "        X_train_augmented.append(shift_image(image, dx, dy))\n",
        "        y_train_augmented.append(label)\n",
        "\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)"
      ],
      "metadata": {
        "id": "3UmOaea02GQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
        "X_train_augmented = X_train_augmented[shuffle_idx]\n",
        "y_train_augmented = y_train_augmented[shuffle_idx]"
      ],
      "metadata": {
        "id": "_X-bdn-B2IS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWozt0n2IJZL"
      },
      "source": [
        "####  **STEP 3. 위에서 확장한 데이터셋을 이용하여, 1번 문제에서 찾은 최적 모델을 훈련시키고, 테스트 세트에서 정확도를 측정해보세요**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo4H-hTRIW7-"
      },
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier(**grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVdwwmSYKDmF"
      },
      "outputs": [],
      "source": [
        "knn_clf.fit(X_train_augmented, y_train_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijlm1VbOKFSN"
      },
      "outputs": [],
      "source": [
        "y_pred = knn_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}